\documentclass[sigplan,screen,acmsmall]{acmart}%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\newif\ifdraft\drafttrue{}
\newif\iflater\latertrue{}

\PassOptionsToPackage{names,dvipsnames}{xcolor}

\settopmatter{printfolios=false,printccs=false,printacmref=false}
\setcopyright{none}

\usepackage{listings}
\usepackage{subcaption}

\lstset{
  mathescape=true,
  frame=none,
  xleftmargin=10pt,
  stepnumber=1,
  belowcaptionskip=\bigskipamount,
  captionpos=b,
  % language=haskell,
  keepspaces=true,
  tabsize=2,
  emphstyle={\bf},
  % commentstyle=\it\color{dkgreen},
  stringstyle=\mdseries\ttfamily,
  showspaces=false,
  keywordstyle=\bfseries\ttfamily,
  columns=flexible,
  basicstyle=\footnotesize\ttfamily,
  showstringspaces=false,
  % morecomment=[l]\%,
  % moredelim=**[is][\color{dkgreen}]{@}{@}
}

\include{macros}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newtheorem{claim}{Claim}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2025/02}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Fail Faster}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Cynthia Richey}
\affiliation{%
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \state{Pennsylvania}
  \country{USA}
}

\author{Joseph W. Cutler}
\affiliation{
  \institution{University of Pennsylvania}
  \city{Philadelphia}
  \state{Pennsylvania}
  \country{USA}
}

\author{Harrison Goldstein}
\affiliation{%
  \institution{University of Maryland}
  \city{College Park}
  \state{Maryland}
  \country{USA}
}

\author{Benjamin C. Pierce}
\affiliation{%
 \institution{University of Pennsylvania}
 \city{Philadelphia}
 \state{Pennsylvania}
 \country{USA}}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Richey and Cutler et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract} \tr{Abstract needs a lot of work.}
Property-based testing (PBT) is a software testing approach that verifies a system against a large suite of automatically-generated inputs. Since testing pipelines typically run under strict time constraints, PBT generators must produce inputs as quickly as possible to maximize the likelihood of finding bugs in the time available. However, existing PBT libraries often prioritize generality at the cost of performance. We introduce \texttt{waffle\_house}, a high-performance generator library that uses staging, a lightweight compilation technique, to eliminate many common generator abstractions. To evaluate \texttt{waffle\_house}, we design a novel benchmarking methodology that compares generators based on program equivalence, isolating performance improvements from differences in input distribution. Using this methodology, we compare \texttt{waffle\_house} to a leading generator library, and, through extensive evaluation over a diverse range of generators, demonstrate that \texttt{waffle\_house} significantly improves generation speed and resource efficiency while matching \texttt{base\_quickcheck}'s expressiveness.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007</concept_id>
       <concept_desc>Software and its engineering</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006</concept_id>
       <concept_desc>Software and its engineering~Software notations and tools</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011072</concept_id>
       <concept_desc>Software and its engineering~Software libraries and repositories</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011041.10011046</concept_id>
       <concept_desc>Software and its engineering~Translator writing systems and compiler generators</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering}
\ccsdesc[500]{Software and its engineering~Software notations and tools}
\ccsdesc[500]{Software and its engineering~Software libraries and repositories}
\ccsdesc[500]{Software and its engineering~Translator writing systems and compiler generators}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Property-based testing, Generators, Staging, Meta-programming}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

\received{--}
\received[revised]{--}
\received[accepted]{--}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

\jwc{This paper is about ``Strict functional languages like OCaml and Scala'', but we'll focus on OCaml for presentation.}


Property-based testing (PBT) is a widely-used testing framework consisting of
two key components: a set of \textit{properties} that a system must satisfy, and
a large number of \textit{inputs} to that system. In contrast to traditional
unit testing, where inputs are hand-written, PBT users create a random-input
\textit{generator} that automatically produces inputs. Sometimes, this process
can itself be automated through the use of PBT libraries that synthesize
generators from type definitions; however, when inputs are required to maintain
invariants not communicated by the type, users must write a custom generator (or
filter out a broad class of invalid inputs). 

Writing ``good" generators—those that uncover more bugs in the system under
test—is challenging. Much effort has been dedicated to this problem, often by
developing sophisticated domain-specific languages for specifying constrained
generators. However, these approaches do not always reflect the needs of real
PBT users. Under ideal conditions, a PBT suite would continue to run
until it stopped finding bugs, real-world usage patterns are very different; a
study of expert PBT users reported time budgets of between 50 milliseconds and
30 seconds for their test suites~\cite{inpractice}. Consequently, generation
time is a significant factor in PBT efficacy---that is, if a generator can
produce inputs twice as fast, it has twice as many chances within a given time
bound to find a bug. Therefore, it is imperative that PBT libraries are built
with performance in mind.

To better understand and address performance challenges in the landscape of PBT
generators, we explore popular libraries across several widely-used programming
languages. We find that the flexibility of these libraries comes at a cost to 
performance,
introducing abstraction overhead, frequent boxing and unboxing, and avoidable
allocations (which lead to costly garbage collection pauses). We focus primarily 
on OCaml's \bq, selected for its efficiency relative to other OCaml PBT libraries 
and its integration with industrial build systems, where it is expected to run 
within tight time constraints. These
inefficiencies raise a fundamental question: how can PBT libraries produce code
that is both efficient \textit{and} general? By analyzing
\bq\ and similar libraries in other languages \tr{Rust?
More?}, we provide a broader perspective on common performance challenges in PBT
and explore potential strategies for more efficient generator implementations.

Our solution is \name, a generator library that preserves
\bq’s functionality while improving performance through
\textit{staged metaprogramming} (staging). Staging is a lightweight,
domain-specific compilation technique that allows us to completely eliminate the
runtime overhead of many common generator abstractions. \jwc{This relies on the fact that the code of generators is known statically at compile time} For instance, in
\name, monadic operations are zero-cost.
\name’s staged eliminates unnecessary allocations,
generates static control structures, and leverages unboxed integer libraries to
achieve performance improvements over \texttt{base\_quickcheck}, making it
well-suited to real-world PBT applications.

We present a new methodology for evaluating the relative effectiveness of PBT
generators. Prior work has compared generators based on bug-finding ability: 
generators are considered equally effective if they find bugs in a
system at the same rate over a large number of trials ~\cite{etna}. However,
because \name\ preserves the semantics of
\bq, a \name\ generator produces exactly
the same inputs as its \bq\ counterpart. By comparing
generators based on \textit{program equality}, we ensure that any speedups in
bug-finding ability stem from performance enhancements rather than variations in
input distribution. This approach establishes a foundation for benchmarking
optimizations that enhance performance without compromising expressiveness.

Finally, we conduct an extensive evaluation, implementing both type-derived and
custom generators in \name\ and \bq. Our
generators produce a diverse range of inputs, including recursive data
structures, lambda calculus terms, and regular expressions. We benchmark
generation time, resource usage, and time-to-failure for each pair of staged and
unstaged generators, demonstrating that \name\ achieves
significant gains in speed and resource.

In summary, we dramatically improve the bug-finding effectiveness of PBT generators
by optimizing them for speed. In speicific, we make the following contributions:
\begin{enumerate}
    \item An empirical analysis of the sources of inefficiency in PBT
    generators. \jwc{And an argument that PBT generator libraries should be engineered for performance}
    \item A library, \name, which offers efficient \jwc{performant?} generator \proposechange{functions}{combinators} through the
    use of staged metaprogramming; this is the first known application of metaprogramming to PBT.
    \item The insight that generators should be compared by program equality 
    \item An evaluation demonstrating the improved performance of generators constructed
    using our library in a controlled comparison.

\end{enumerate}

\section{Background}


\jwc{In this paper, we'll use OCaml to illustrate the ideas, but the concepts are portable to other languages: see Section~\ref{subsection:other-langs}}

\subsection{Property-Based Testing}
\jwc{Usual spiel about pbt and generators: here's the BQ generator library, it has return and bind, this is what they're for.}

\begin{lstlisting}
module Bq = struct
  type 'a t = int -> SR.t -> 'a

  let return (x : 'a) : 'a t = fun size seed -> x

  let bind (g : 'a t) (f : 'a -> 'b t) : 'b t =
    fun size seed ->
      let x = g size seed in
      (f x) size seed

  let gen_int (lo : int) (hi : int) : int t =
    fun size seed -> SR.int seed lo hi
end
\end{lstlisting}

\jwc{\texttt{gen\_int} here is really \texttt{int\_uniform\_inclusive}. I also think we should completely omit named arguments in the paper so we don't confuse with splices.}

\jwc{Here's an example of a generator: you can sample from it and it gives you pairs of ints, one less than the other.}

\begin{lstlisting}
let int_pair : (int * int) Bq.t =
  let%bind x = Bq.gen_int 0 100 in
  let%bind y = Bq.gen_int 0 x in
  return (x,y)
\end{lstlisting}

\jwc{This desugars to...}

\begin{lstlisting}
let int_pair : (int * int) Bq.t =
  Bq.bind (Bq.gen_int 0 100) (fun x ->
    Bq.bind (Bq.gen_int 0 x) (fun y ->
      Bq.return (x,y)
  ))
\end{lstlisting}


\subsection{Staged Metaprogramming}

\jwc{A good quick presentation of staged metaprogramming is here, in section 6.
https://www.cl.cam.ac.uk/~jdy22/papers/a-typed-algebraic-approach-to-parsing.pdf
}

\jwc{Staged metaprogramming has a long history as a technique for eliminating the runtime overhead of abstractions,
specializing programs at an earlier stage to run more efficiently at a later stage.}

\jwc{For the purposes of this paper, we will only use two stages: compile time, and run time.}


\jwc{
  \begin{itemize}
    \item The \texttt{'a code} type, quote, splice, stage distinction.
    \item The difference between \texttt{('a -> 'b) code} and \texttt{'a code -> 'b code}
    \item We can convert one way, but not the other.
    \item Functions \texttt{'a code -> 'b code} ``fuse''.
    \begin{itemize}
      \item Consider writing \texttt{even . succ}. This
      \item Consider \texttt{even\_c : int code -> bool code = fun cx -> .<.~cx mod 2 == 0>.} and \texttt{succ\_c : int code -> int code = fun cx -> .< .~x + 1 >.}
      \item If you do \texttt{to\_dyn (even\_c . succ\_c)}, you get \texttt{fun x -> (x + 1) mod 2 == 0}. Composing functions from code to code, and then \emph{only at the end} stamping out
      a dynamic function value eliminates the function abstraction.
    \end{itemize}
    \item This is the basis of (WORD). By defining a library with functions with types like \texttt{'a code -> 'b code}, we can ensure that the
    abstractions the library introduces are fully eliminated at compile time.
  \end{itemize}
}

\subsection{Other Languages and Libraries}
\label{subsection:other-langs}

\jwc{TODO: Move this section later (cf conversation in WH meeting 3/7/25)}

\tr{Here's where we talk about what's going on in the world, and ultimately make the argument that \bq{} is the best tool to reproduce.}

\jwc{Note that this explanation require some prior note of exactly *why* BQ is slow... i.e. the abstraction overhead of the library is high.}

\jwc{
  \begin{itemize}
    \item Scala. Functional abstractions like QC generators are known to be costly in Scala, that's why they have LMS (in Scala 2, and Macros in Scala 3). Example: parser combinators (``On Staged Parser Combinators for Efficient Data Processing''), functional data structures (\href{https://ppl.stanford.edu/papers/popl13_rompf.pdf}{Link}), web programming (``Efficient High-Level Abstractions for Web Programming'').
    Al of this should still work in scala. Could easily be incorporated into ScalaCheck, with minor modification: ScalaCheck uses a state monad to thread around the seed, instead of a stateful one (like BQ), or a splittable one (like Haskell). So you have to adapt to that. But same diff.
    \item Haskell: GHC does a lot of these optimizations already, since the code is pure. Since QC generators are relatively small programs,
    GHC has little trouble specializing them. Of course, this is not guaranteed. A version of this idea can easily be ported to the original QC with template haskell, to guarantee
    the highest-performance generators.
    \item Rust: Not GC'd, so no alloc overhead but bind'd generators still dispatch through runtime data.
  \end{itemize}
}

\subsection{\bq}

\section{Why is \bq\ slow, and how can we fix it?}

\jwc{NOTE: We can simplify this further by getting rid of the size parameter. Make the story even cleaner, I think!}

\jwc{
  \begin{itemize}
    \item It's been long-known that clean functional abstractions have a runtime overhead (this should be familiar by this time in the paper).
    \item How does (simplified) BQ work?
    \begin{itemize}
      \item The basic generator type: \texttt{'a generator = int -> SR.t -> 'a}. Size and random seed to deterministic value. (note: \texttt{SR.t} is a mutable seed)
      \item This gets a monad intance in the obvious way (show code).
      \item Also show the code for \texttt{int}, how it calls the underlying SR function.
    \end{itemize}
    % \item Note that \emph{extensionally} \texttt{generate (create (fun size random -> e)) size random = e}, but the OCaml compiler does not always perform this optimization, or do the inlining required to expose it.
    % (When sufficiently obfuscated behind returns and binds ...) This program compiles to code that (1) allocates the closure for `e', (2) passes it to create (which returns the closure), and then calls (3) generate, which immediately jumps into the closure.
    \item Show benchmarks of the running example, versus the version where you inline everything. ()
    \item Let's look at the running example: inline it all the way.
  \end{itemize}
}

\begin{lstlisting}
let int_pair : (int * int) Bq.t =
  Bq.bind (Bq.gen_int 0 100) (fun x ->
    Bq.bind (Bq.gen_int 0 x) (fun y ->
      Bq.return (x,y)
  ))

let int_pair_inlined : (int * int) Bq.t
  fun sr ->
    let x = Splittable_random.int sr ~lo:0 ~hi:100 in
    let y = Splittable_random.int sr ~lo:0 ~hi:x in
    (x,y)
\end{lstlisting}

\jwc{Show benchmark difference between these two generators: the benchmark is in \texttt{waffle-house/handwritten-ocaml/bin/basic-compare.ml}. It's about 2x. (see comment in latex here.)}

\jwc{The native code OCaml compiler, even with -O3, fails to specialize this code and eliminate the overhead of this abstraction --- inlining all of the funciton definitions and then performing beta-reductions speeds up sampling by a factor of 2.}

% ┌───────┬──────────┬─────────┬────────────┐
% │ Name  │ Time/Run │ mWd/Run │ Percentage │
% ├───────┼──────────┼─────────┼────────────┤
% │ bq    │  70.47ns │  78.00w │    100.00% │
% │ fused │  35.86ns │  78.00w │     50.89% │
% └───────┴──────────┴─────────┴────────────┘

\jwc{The overhead of the abstraction is 2x.
The reality is actually worse: actual base-quickcheck includes even more indirection in its type.}

\jwc{
The problem is plain: while the abstractions that PBT libraries like base quickcheck provide are indespensible for writing idiomatic generators, the performance overhead of using them is dramatic.
The compiler (and flambda) uses heuristics (\href{https://ocaml.org/manual/5.3/flambda.html}{here}) to decide when to specialize and inline code, and these heuristics cannot guarantee that generator abstractions are zero-cost.
These heuristics are also extremely conservative about inlining and specializing recursive functions, which all generators of recursive data types must be.
}

\tr{Each of these consist of an explanation of the problem and pseudocode outlining the solution.}
\subsubsection{Monadic Bind}

\jwc{
  \begin{itemize}
    \item While it's the ``correct'' abstraction for generators, using a monadic interface prevents the compiler from specializing generator code. Using monadic bind and return obscures the control and data flow of a generator from the compiler. This is
    compounded when handling recursive functions.
    \item In cases where the compiler cannot statically eliminate them, running a monadic bind allocates a short-lived closure: we allocate a closure for the continuation, and then immediately jump into it.
    \item Each closure allocation is relatively cheap (they're going to be minor allocations since they're short-lived), but doing lots of allocation in a generation hot loop adds up fast, and each minor allocation brings us closer to the next costly GC pause.
  \end{itemize}
}

\subsubsection{Expensive Combinators}
\jwc{Many combinators like \texttt{union} and \texttt{weighted\_union} needlessly allocate large data structures in the generation hot path.
Using a combination of staging and more careful algorithm design, we can avoid this overhead.
}

\begin{lstlisting}
  let of_weighted_list alist =
  let weights, values = List.unzip alist in
  let value_array = Array.of_list values in
  let total_weight, cumulative_weight_array =
    let array = Array.init (Array.length value_array) ~f:(fun _ -> 0.) in
    let sum =
      List.foldi weights ~init:0. ~f:(fun index acc weight ->
        let acc' = acc +. weight in
        array.(index) <- acc';
        acc'
      )
    in
    sum, array
  in
  create (fun ~size:_ ~random ->
    let choice = Splittable_random.float random ~lo:0. ~hi:total_weight in
    match
      Array.binary_search
        cumulative_weight_array
        ~compare:Float.compare
        `First_greater_than_or_equal_to
        choice
    with
    | Some index -> value_array.(index)
    | None -> assert false
   )
\end{lstlisting}

\jwc{This builds the cdf of the distribution, samples from 0 to the total, and binary searches through the array to find the bucket.}
\jwc{Allocating this array is unnecessary: we can simply compute the total weight, sample \texttt{x} between 0 and the total, and then walk the list accumulating the sum, until the accumulator exceeds \texttt{x}. Since in practice the list of possible options is quite small (usually at most 10 in practice), the linear time scan is going to be much faster.}
\jwc{(The point of this para will just be to emphasize that it's almost always better to be allocation-aware, instead of algorithmically clever.)}

\jwc{Moreover, the possible options is almost always statically known in practice: you use weightedunion to generate (say) a datatype with possible
variants, whose options are known at compile time.
Put more simply, you basically always call weighted union with an \emph{explicit list}: For this reason, you should not have to incur the cost of allocating this list at runtime.}

\jwc{ofc, sometimes you only know the list at runtime (see the STLC generator for an example), so you the library also includes this.}

% \subsubsection{Function call overhead}
\subsubsection{Boxed RNG}

The core of any PBT generator library is a random-number generator. Following
the original Haskell QuickCheck, \bq uses the SplitMix algorithm \cn,
implemented as an OCaml library called \texttt{Splittable\_random}. The precise
details of how SplitMix works are unimportant for the present paper, but the
main operations are defined in terms of bitwise operations on 64-bit integers.
However, due to implementation details related to the garbage collector, all
runtime OCaml values are either (a) pointers to a block of memory, or (b) 63-bit ``immediate'' values.
As such, the OCaml type of 64-bit ingeters, \texttt{int64}, is \emph{boxed}: it
is a pointer to a block of memory that contains a 64-bit integer.  This means
that \emph{all} \texttt{int64} operations (both arithmetic and bitwise) must
allocate memory cells to contain their output.

This has a significant impact on the performance of generators. A single call to
one of the \bq library functions may sample from \texttt{Splittable\_random}
multiple times, and each sample from \texttt{Splittable\_random} allocates 9
words \jwc{this is a call to \texttt{next\_int64}}.  While seemingly small, we
will see in Section~\ref{section:eval} that this amount of allocation has a
significant impact on significant.

In Section~\ref{subsection:faster-rng}, we show how our library mitigates this
performance hit by using OCaml's FFI to reimplement the RNG in non-allocating C code.
We also discuss how the ``unboxed types'' extension to the OCaml compiler \cn could instead be used
to the same effect without leaving OCaml.

It is worth noting that the inefficiency of boxed \texttt{int64}s is not due to
the abstraction overhead of the generator DSL itself, but simply due to language
implementation and algorithm choices. We include this discussion --- and
the corresponding evaluation
--- to demonstrate the testing-time savings of taking seriously the notion that PBT libraries
should be engineered for performance.

\section{\name: A Library for Staged Generators}

\jwc{Usual introduction to this section, corresponding to how we talked about it in the intro}

\jwc{
  \begin{itemize}
    \item To eliminate this runtime overhead and generate efficient code, we do a usual ``binding-time analysis''.
    \item The crux of this binding-time analysis is that while generators are `just' values of type \texttt{'a t}, in practice they are always \emph{completely statically defined}: one never
    computes a generator dynamically at test time.
    \item The size and the random seed are only known at run-time (the later stage), but the code of the generator itself is known at compile time.
    \item This means the generator type should be \texttt{int code -> SR.t code -> 'a code}: a statically known-function from dynamically-known int and seed to dynamically-determined result.
  \end{itemize}
}

\subsection{Basic Design}

A generator of \texttt{'a}s is then a (compile-time) function \texttt{int code -> Random.t code -> 'a code}.

\jwc{Note that some of this is a lie, but it's a good first cut: point to the section on \emph{The Trick} to see the real version.}

\jwc{
  \begin{itemize}
    \item The simplest combinators are presented below.
    \item \texttt{return} is the constant generator, given code for \texttt{x : 'a}, it gives the generator which always generates \texttt{x}
    \item \texttt{bind} is like BQ's bind --- sequencing generators by passing the result of one to another --- except that the continuation gets access to the
    \texttt{code} for the result of running the first generator. At compile time, we know only that \texttt{g} will return \emph{some} \texttt{a}, but we do not get access to the particular \texttt{a}.
    \item Bind takes code for the size and seed, and returns code that first let-binds the result of the first generator.
    The function application \texttt{g size\_c random\_c} runs during the first stage, producing the code for the \texttt{a}. This is then spliced into the quote: the specialized code of the generator \texttt{g}
    put on the right-hand side of the let. Then, we splice in the code for the continuation, passing first the variable x, and the same size and random seed.
  \end{itemize}
}

\begin{lstlisting}

module Gen = struct
  type 'a t = int code -> Random.t code -> 'a code

  let return (cx : 'a code) : 'a t = fun size_c random_c -> cx

  let bind (g : 'a t) (k : 'a code -> 'b t) : 'b t =
    fun size_c random_c ->
      .<
        let x = .~(g size_c random_c) in
        .~(k .<x>. size_c random_c)
      >.

  let int (lo : int code) (hi : int code) : int t =
    fun size_c random_c ->
      .< SR.int .~random_c .~lo .~hi >.

  let to_bq (g : 'a code Gen.t) : ('a Bq.t) code =
  .<
    fun size random -> .~(g .<size>. .<random>.)
  >.
end
\end{lstlisting}

\jwc{Conversion to a bq generator}

\jwc{Then show the running example, with }

\begin{lstlisting}
let int_pair_staged : ((int * int) code) Gen.t =
  Gen.bind (Gen.int .<0>. .<100>.) (fun cx ->
    Gen.bind (Gen.int .<0> cx) (fun cy ->
      Gen.return .<(.~cx,.~cy)>.
    )
  )
let int_pair : (int * int) Bq.t code = Gen.to_bq int_pair_staged
====
.<
  fun size random ->
    let x = SR.int random 0 100 in
    let y = SR.int random 0 x in
    (x,y)
.>
\end{lstlisting}

\jwc{So if you write with the \texttt{Gen} combinators and then only call \texttt{to\_bq} at the end, you get something that inlines everything all the way down!}



\subsection{Staging More Combinators}

\jwc{Weighted unions: recall that we should not need to materialize}

% let rec genpick n ws =
% match ws with
% | [] -> { rand_gen = fun ~size_c:_ ~random_c:_ -> Codecps.return .< failwith "Fell of the end of pick list" >. }
% | (k,g) :: ws' ->
%       { rand_gen = 
%         fun ~size_c ~random_c ->
%           Codecps.bind (Codecps.split_bool .< Float.compare .~(v2c n) .~(v2c k) <= 0 >.) (fun leq ->
%             if leq then
%               g.rand_gen ~size_c ~random_c
%             else
%               Codecps.bind (Codecps.let_insertv .< .~(v2c n) -. .~(v2c k) >.) @@ fun n' ->
%               (* let%bind n' =  in *)
%               (genpick n' ws').rand_gen ~size_c ~random_c
%         )
%       }

\begin{lstlisting}
  let weighted_union (weighted_elts : (float code * 'a code) list) : 'a t =
    let sum_code = List.foldr _ in
    let go (rc : int code) (weighted_elts : (float code * 'a code) list) : 'a code =
      match weighted_elts with
      | [] -> .< failwith "Error" >.
      | (wc,xc) :: elts' ->
        .<
          if .~rc <= .~wc then .~xc
          else
            let r' = .~rc - .~wc in
            .~(go .<r'>. elts')
        >.

    fun size_c random_c ->
      .<
        let sum = .~sum_code in
        let r = SR.int .~random_c 0 sum in
        .~(go .<r>. gwcs)
      >.
\end{lstlisting}

Then, if we write

\begin{lstlisting}
let grades : charBq.t gen = to_bq (
  weighted_union [
    (.<3.0>., .<'a'>.);
    (.<2.0>., .<'b'>.);
    (.<1.0>., .<'c'>.);
  ]
)
===
Bq.create (
  fun size random ->
    let sum = 3.0 + 2.0 + 1.0 in
    let r = SR.int random 0 sum in
    if r <= 3.0 then 'a'
    else
      let r' = r - 3.0 in
      if r' <= 2.0 then 'b'
      else
        let r'' = r' - 2.0 in
        if r'' <= 1.0 then 'c'
        else
          failwith "Error"
)
\end{lstlisting}

\subsection{Effect Ordering, and Equivalence is Program Equality}
\jwc{``Wait, why was the defintion of bind like that''?
Careful readers might note that the definition of bind was a little strange. In particular, why not just do this?}
\begin{lstlisting}
  let bind (g : 'a gen) (k : 'a code -> 'b gen) : 'b gen =
    fun size_c random_c ->
      k (g size_c random_c) size_c random_c
\end{lstlisting}
\jwc{The answer is that this doesn't generate the right code! In particular, this definition of bind means that
\texttt{bind (int 0 1) (fun x -> return .<(.~x,.~x)>.)} would generate \texttt{fun size random -> (int random 0 1, int random 0 1)},
which is \emph{not} the desired behavior. (Cite cbn/cbv randomness here).
A splice is a (hygenic) syntactic replacment, so
if a function \texttt{f : 'a code -> 'b code} splices its argument multiple times into its output, the argument code will be directly copied in.
This is why we insert a let-binding in the definition of bind, to ensure that
the explicit sequencing of bind is preserved into explicit sequencing in the
generated code.
}

\jwc{
The library is carefully design to preserve exactly the effect order of BQ. If
you write the same generator in both, they run identically: for the same size
and random seed, they produce the same value.
}

\jwc{Note: tradeoff between maintaining the effect ordering and even more performance.}

\subsection{Size Parameters, A Real Monad Instance, CPS, and ``The Trick''}

\jwc{Introduce the size parameter here. (if you deleted it beforehand.)}

\jwc{
  \begin{itemize}
    \item Careful readers might note that the types of return and bind are not actually the right types.
    \item This means that they aren't compatible with ppx-jane syntax.
    \item We could try a different type, \texttt{type 'a gen = int code -> SR.t code -> 'a}. This has an actual monad instance (show), and ou can write teh combinators of before, with \texttt{'a code gen} everywhere you had \texttt{'a gen} before.
    \item But because the result type isn't always in \texttt{code}, \texttt{bind} can't perform the let-insertion needed to preserve effect ordering.
    \item Instead, we turn to a classic technique from the multistage programming literature: writing our staged program in continuation-passing style.
    \item We define \texttt{type 'a codecps = 'z. ('a -> 'z code) -> 'z code}. This is the polymorphic CPS monad, with the continuation type always in `code'. (Footnote: this is an instance of the \emph{codensity} monad, cf ``Asymptotic Improvement of Computations over Free Monads'')
    (Cite: ``improving binding times without explicit cps conversion'', ``Multi-stage programming with functors and monads: Eliminating abstraction overhead from generic code'', and ``Closure-Free Functional Programming in a Two-Level Type Theory'')
    \item This lets us define the function \texttt{let\_insert : 'a code -> 'a codecps} as \texttt{let\_insert cx = fun k -> k .< let x = .~cx in .~(k .<x>.) >.}.
    \item of course, \texttt{codecps} has the usual monad instance for the CPS monad with a polymorphic result type.
    \item We then define \texttt{type 'a gen = int code -> SR.t code -> 'a codecps}, which lets us have it both ways. the effectful programs like \texttt{int} do their \emph{own} let-insertion, and we get a real monad instance.
  \end{itemize}
}

\jwc{This gives us the final definitions:}

\begin{lstlisting}
module CodeCps = struct
  type 'a t = { cps : 'z. ('a -> 'z code) -> 'z code }

  let return x = {cps = fun k -> k x}

  let bind (x : 'a t) (f : 'a -> 'b t) : 'b t =
    {cps = fun k -> x.cps (fun a -> (f a).cps k)}

  let run (t : 'a code t) : 'a code = t.cps (fun x -> x)

  let let_insert (cx : 'a code) : 'a code t =
    {cps = fun k -> k .< let x = .~cx in .~(k .<x>.) >.}
end

module Gen = struct
  type 'a t = int code -> SR.t code -> 'a CodeCps.t

  let return (x : 'a) : 'a t = fun _ _ -> Codecps.return x

  let bind (g : 'a t) (f : 'a -> 'b t) =
    fun size random ->
      CodeCps.bind (g size random) (fun x ->
        (f x) size random
      )
  
  let int (lo : int code) (hi : int code) : int code t =
    fun size random ->
      let_insert .< SR.int .~random .~lo .~hi >.
end
\end{lstlisting}

\jwc {
And this has the desired effect that
\texttt{bind (int .<0>. .<1.>) (fun x -> return .<(.~x,.~x)>.)} generates
\texttt{fun size random -> let x = SR.int random 0 1 in (x,x)}
}

\subsubsection{The Trick}

\subsection{Staged Type-Derived Generators}

\jwc{Todo: Thia}

\jwc{This is 3-stage metaprogramming! There's PPX-time, compile time, and run-time.}

\subsection{Faster Random Number Generators}
\label{subsection:faster-rng}

\jwc{
  \begin{itemize}
    \item 
  \end{itemize}
}

\jwc{All of this can be done with Jane Street bleeding-edge compiler extensions, though these are not yet compatible with MetaOCaml.}

\section{Evaluation}

\subsubsection{Implementation}
\subsection{Benchmarking speed \& resource usage}

\jwc{NOTE: we should test generator speed across both languages, but speed -> bugfinding ability in only OCaml.}
\jwc{
  Baseline generators to test speed in both languages:
  \begin{itemize}
    \item Single int
    \item Pair of ints, constrained
    \item List of ints
  \end{itemize}
}
\subsection{Impact on bug-finding ability}
\section{Conclusion \& Future Work}
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}


%%
%% If your work has an appendix, this is the place to put it.
\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.
